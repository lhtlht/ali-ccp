{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "from tqdm import tqdm\n",
    "from common_val import *\n",
    "from common_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 公共函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_list_split(x):\n",
    "    feature_dict = defaultdict(list)\n",
    "    for fea in x.split('\\x01'):\n",
    "        field = re.split('\\x02', fea)\n",
    "        #fea = re.split('\\x03', field[1])\n",
    "        #feature_dict[field[0]].append({'feature_id':fea[0], 'value':fea[1]})\n",
    "        feature_dict[field[0]].append(field[1])\n",
    "    return feature_dict\n",
    "\n",
    "def mul_list_to_dict(x):\n",
    "    feature_dict = dict()\n",
    "    for item in x:\n",
    "        item = item.split('\\x03')\n",
    "        \n",
    "        feature_dict[item[0]] = item[1]\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = ['101','121','122','124','125','126','127', '128', '129', '150_14', '127_14', '109_14', '110_14']\n",
    "item_features = ['205','206','207', '210','216','508','509', '702', '853', '301']\n",
    "\n",
    "fea_cols = ['common_feature_index', 'feature_num2', 'feature_list2']\n",
    "sample_cols = ['sample_id', 'click', 'conversion', 'common_feature_index', 'feature_num1', 'feature_list1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 公共特征预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_fea_fn(data):\n",
    "    data['fea_dict2'] =  data['feature_list2'].map(feature_list_split)\n",
    "    data['userid'] = data['fea_dict2'].map(lambda x: int(x['101'][0].split('\\x03')[0]) if '101' in x else 0) # 用户ID\n",
    "    data['usercate1'] = data['fea_dict2'].map(lambda x: int(x['121'][0].split('\\x03')[0]) if '121' in x else 0) # 用户的一种分类ID\n",
    "    data['usercate2'] = data['fea_dict2'].map(lambda x: int(x['122'][0].split('\\x03')[0]) if '122' in x else 0) # 用户的一种分类ID\n",
    "    data['usercate1'] = data['usercate1'].map(lambda x: x-3438658+1 if x!=0 else x)\n",
    "    data['usercate2'] = data['usercate2'].map(lambda x: x-3438755+1 if x!=0 else x)\n",
    "    \n",
    "    data['gender'] = data['fea_dict2'].map(lambda x: int(x['124'][0].split('\\x03')[0]) if '124' in x else 0) # 用户性别分类ID\n",
    "    data['gender'] = data['gender'].map({3438769:2, 3438768:1, 0:0})\n",
    "\n",
    "    data['age'] = data['fea_dict2'].map(lambda x: int(x['125'][0].split('\\x03')[0]) if '125' in x else 0) # 用户年龄分类ID\n",
    "    data['age'] = data['age'].map(lambda x: x-3438770+1 if x!=0 else x)\n",
    "    \n",
    "    data['user_consume1'] = data['fea_dict2'].map(lambda x: int(x['126'][0].split('\\x03')[0]) if '126' in x else 0) # 用户消费水平分类I    \n",
    "    data['user_consume2'] = data['fea_dict2'].map(lambda x: int(x['127'][0].split('\\x03')[0]) if '127' in x else 0) # 用户消费水平分类II\n",
    "    data['user_consume1'] = data['user_consume1'].map({3438777:1, 3438778:2, 3438779:3, 0:0})\n",
    "    data['user_consume2'] = data['user_consume2'].map({3438780:1, 3438781:2, 3438782:3, 0:0})\n",
    "    \n",
    "    data['work'] = data['fea_dict2'].map(lambda x: int(x['128'][0].split('\\x03')[0]) if '128' in x else 0) # 用户是否就业\n",
    "    data['work'] = data['work'].map({3864885:1, 3864886:2, 0:0})\n",
    "    \n",
    "    data['location'] = data['fea_dict2'].map(lambda x: int(x['129'][0].split('\\x03')[0]) if '129' in x else 0) # 用户地理信息分类ID\n",
    "    data['location'] = data['location'].map({3864887:1, 3864888:2, 3864889:3, 3864890:4, 0:0})\n",
    "    \n",
    "#     data['user_intention_node_count'] = data['fea_dict2'].map(lambda x: mul_list_to_dict(x['150_14']) if '150_14' in x else {}) # 用户意图ID以及用户在该意图上的历史行为累积数量\n",
    "#     data['user_shop_brand_count'] = data['fea_dict2'].map(lambda x: mul_list_to_dict(x['127_14']) if '127_14' in x else {}) # 商品品牌ID以及用户在该店铺上的历史行为累积数量*\n",
    "#     data['user_shop_cate_count'] = data['fea_dict2'].map(lambda x: mul_list_to_dict(x['109_14']) if '109_14' in x else {}) # 商品类目ID以及用户在该类目上的历史行为累积数量*\n",
    "#     data['user_shop_count'] = data['fea_dict2'].map(lambda x: mul_list_to_dict(x['110_14']) if '110_14' in x else {}) # 商品店铺ID以及用户在该店铺上的历史行为累积数量*\n",
    "    \n",
    "    data['user_intention_count'] = data['fea_dict2'].map(lambda x: x['150_14']) # 用户意图ID以及用户在该意图上的历史行为累积数量\n",
    "    data['user_brand_count'] = data['fea_dict2'].map(lambda x: x['127_14']) # 商品品牌ID以及用户在该店铺上的历史行为累积数量*\n",
    "    data['user_cate_count'] = data['fea_dict2'].map(lambda x: x['109_14']) # 商品类目ID以及用户在该类目上的历史行为累积数量*\n",
    "    data['user_shop_count'] = data['fea_dict2'].map(lambda x: x['110_14']) # 商品店铺ID以及用户在该店铺上的历史行为累积数量*\n",
    "    \n",
    "    # 后续字段类型转换\n",
    "    data['usercate1'] = data['usercate1'].astype('category')\n",
    "    data['usercate2'] = data['usercate2'].astype('category')\n",
    "    data['gender'] = data['gender'].astype('category')\n",
    "    data['age'] = data['age'].astype('category')\n",
    "    data['user_consume1'] = data['user_consume1'].astype('category')\n",
    "    data['user_consume2'] = data['user_consume2'].astype('category')\n",
    "    data['work'] = data['work'].astype('category')\n",
    "    data['location'] = data['location'].astype('category')\n",
    "    data.drop(columns=['feature_num2','feature_list2', 'fea_dict2'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = pd.read_csv(common_features_train_csv, header=None, names=fea_cols, iterator=True,chunksize = 100000)\n",
    "fea_test = pd.read_csv(common_features_test_csv, header=None, names=fea_cols, iterator=True,chunksize = 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  内存大，一次性读入处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read done'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'done!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_train = pd.read_csv(common_features_train_csv, header=None, names=fea_cols)\n",
    "'read done'\n",
    "user_fea_fn(fea_train)\n",
    "'done!'\n",
    "fea_train.to_pickle(os.path.join(data_path2, f'fea_train.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read done'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'done!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_test = pd.read_csv(common_features_test_csv, header=None, names=fea_cols)\n",
    "'read done'\n",
    "user_fea_fn(fea_test)\n",
    "'done!'\n",
    "fea_test.to_pickle(os.path.join(data_path2, f'fea_test.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  内存小，一次性读入处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for chunk_df in fea_train:\n",
    "    print(i,chunk_df.shape)\n",
    "    user_fea_fn(chunk_df)\n",
    "    chunk_df.to_pickle(os.path.join(data_path2, f'fea_train{i}.pkl'))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (100000, 3)\n",
      "1 (100000, 3)\n",
      "2 (100000, 3)\n",
      "3 (100000, 3)\n",
      "4 (100000, 3)\n",
      "5 (100000, 3)\n",
      "6 (100000, 3)\n",
      "7 (100000, 3)\n",
      "8 (84212, 3)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for chunk_df in fea_test:\n",
    "    print(i,chunk_df.shape)\n",
    "    user_fea_fn(chunk_df)\n",
    "    chunk_df.to_pickle(os.path.join(data_path2, f'fea_test{i}.pkl'))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 样本特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = pd.read_csv(sample_skeleton_train_csv, header=None, names=sample_cols, iterator=True,chunksize = 2500000)\n",
    "sample_test = pd.read_csv(sample_skeleton_test_csv, header=None, names=sample_cols, iterator=True,chunksize = 2500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def item_fea_fn(data):\n",
    "    data['fea_dict1'] =  data['feature_list1'].map(feature_list_split)\n",
    "    \n",
    "    data['itemid'] = data['fea_dict1'].map(lambda x: int(x['205'][0].split('\\x03')[0]) if '205' in x else 0) # 商品ID\n",
    "    data['item_cate'] = data['fea_dict1'].map(lambda x: int(x['206'][0].split('\\x03')[0]) if '206' in x else 0) # 商品所属类目ID\n",
    "    data['shopid'] = data['fea_dict1'].map(lambda x: int(x['207'][0].split('\\x03')[0]) if '207' in x else 0) # 商品所属店铺ID\n",
    "    data['brandid'] = data['fea_dict1'].map(lambda x: int(x['216'][0].split('\\x03')[0]) if '216' in x else 0) # 商品的品牌ID\n",
    "    data['business'] = data['fea_dict1'].map(lambda x: int(x['301'][0].split('\\x03')[0]) if '301' in x else 0) # 业务场景信息的一种分类表示\n",
    "    \n",
    "    # 109_14:商品类目ID以及用户在该类目上的历史行为累积数量*和206域商品所属类目IDe的组合特征：浮点值 商品所属类目ID 经验证，一一对应关系\n",
    "    data['user_cate_val'] = data['fea_dict1'].map(lambda x:x['508'][0].split('\\x03')[1] if len(x['508'])>0 else np.NaN) \n",
    "    # 110_14和207域的组合特征：浮点值,经验证，一一对应关系\n",
    "    data['user_shop_val'] = data['fea_dict1'].map(lambda x:x['509'][0].split('\\x03')[1] if len(x['509'])>0 else np.NaN) \n",
    "    # 127_14和216域的组合特征：浮点值 经验证，一一对应关系\n",
    "    data['user_brand_val'] = data['fea_dict1'].map(lambda x:x['702'][0].split('\\x03')[1] if len(x['702'])>0 else np.NaN) \n",
    "    \n",
    "    data['user_intentions'] = data['fea_dict1'].map(lambda x:[i.split('\\x03')[0] for i in x['210']]) # 商品关联用户意图ID：多值\n",
    "    data['user_intentions_val'] = data['fea_dict1'].map(lambda x:x['853']) # 150_14和210域的组合特征：多值，浮点值\n",
    "    data.drop(columns=['feature_num1','feature_list1', 'fea_dict1'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_fea_train = pd.read_pickle(os.path.join(data_path2, f'fea_train.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (2500000, 6)\n",
      "2 (2500000, 6)\n",
      "3 (2500000, 6)\n",
      "4 (2500000, 6)\n",
      "5 (2500000, 6)\n",
      "6 (2500000, 6)\n",
      "7 (2500000, 6)\n",
      "8 (2500000, 6)\n",
      "9 (2500000, 6)\n",
      "10 (2500000, 6)\n",
      "11 (2500000, 6)\n",
      "12 (2500000, 6)\n",
      "13 (2500000, 6)\n",
      "14 (2500000, 6)\n",
      "15 (2500000, 6)\n",
      "16 (2300135, 6)\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for sam_chunk in sample_train:\n",
    "    print(i,sam_chunk.shape)\n",
    "    item_fea_fn(sam_chunk)\n",
    "    \n",
    "    sam_chunk = sam_chunk.merge(common_fea_train, how='left', on='common_feature_index')\n",
    "    sam_chunk.to_pickle(os.path.join(data_path2, f'sample_train{i}.pkl'))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
